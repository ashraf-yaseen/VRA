{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import time \n",
    "\n",
    "from emb.bm25 import BM25Class\n",
    "from utils.find_ranking_citation import CitationRanking\n",
    "from utils.write_result import WriteResult\n",
    "from utils.utils import sort_this\n",
    "from utils.configuraiton import Rec_configuration \n",
    "from utils.eval import Metrics\n",
    "from utils.data_loading import DataLoading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from string import punctuation\n",
    "punc = set(punctuation)\n",
    "\n",
    "\n",
    "def clean(str):\n",
    "    temp = []\n",
    "    for word in str.split():\n",
    "        if word in stop_words or word in punc:\n",
    "            continue\n",
    "        temp.append(word)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.A building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Master:\n",
    "    def __init__(self, rerank = False):\n",
    "        self.rec_conf = Rec_configuration()\n",
    "        self.article_title, self.article_abstract, self.geo_title, \\\n",
    "        self.geo_summary, self.citation_data = DataLoading().get_all_details() #we should get actual citations\n",
    "        self.auto_rank = CitationRanking(self.citation_data)\n",
    "        self.write_res = WriteResult()\n",
    "        choose = list(self.citation_data.keys())\n",
    "        self.geo_test_data = [key for key in choose if self.citation_data[key] != []] #76,064\n",
    "        #self.rr = ReRankingTitle() # i definitely need to work on this as well (re-ranking title using bert)\n",
    "        self.top_threshold = 10 #sounds nice\n",
    "        self.rerank = rerank\n",
    "        self.res_addr = self.rec_conf.result_address_bm25 #subject to change\n",
    "        self.model_addr = self.rec_conf.model_path_bm25\n",
    "\n",
    "    def process(self):\n",
    "        #check paths and check vecs  \n",
    "        bm25 = BM25Class(self.model_addr)\n",
    "        pmids, bm25_vecs = None, None #this should be loading something\n",
    "\n",
    "        # This is for loading the pre-trained bert models.\n",
    "        if bm25_vecs is not None and pmids is not None:\n",
    "            print('load trained models and encoded publications vectors')\n",
    "            '''\n",
    "            \n",
    "            '''\n",
    "        else:\n",
    "            print('Building models')\n",
    "            joined_dict_article = {}\n",
    "            for pmid in self.article_title: #for articles, encoding the articles\n",
    "                #print('pmid')\n",
    "                #print(pmid)\n",
    "                if (self.article_title[pmid] + self.article_abstract[pmid]).strip() != '':\n",
    "                    joined_dict_article[pmid] = clean(self.article_title[pmid] + ' ' + self.article_abstract[pmid])\n",
    "            #should be some training here, otherwise just do the easiest encodinh\n",
    "            bm25.create_model(joined_dict_article)\n",
    "    \n",
    "        joined_dict_geo = {} # maxium: 76,064\n",
    "        # screening first for those geo_ids with pmids \n",
    "        for geo_id in self.geo_test_data:\n",
    "            print('geo_id')\n",
    "            print(geo_id)\n",
    "            if (self.geo_title[geo_id] + self.geo_summary[geo_id]).strip() != '':\n",
    "                #only get the ones with actual texts\n",
    "                joined_dict_geo[geo_id] = clean(self.geo_title[geo_id] + ' ' + self.geo_summary[geo_id])\n",
    "        with open(self.res_addr + 'smallbase/joined_dict_geo', 'wb') as handle:\n",
    "            pickle.dump(joined_dict_geo, handle, protocol=pickle.HIGHEST_PROTOCOL)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    x = Master(rerank = False)\n",
    "    x.process()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.B evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, citation_data = DataLoading().get_all_details() #we should get actual citations\n",
    "auto_rank = CitationRanking(citation_data)\n",
    "write_res = WriteResult()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_similarity_dict = {}\n",
    "for step, (k,v) in enumerate(joined_dict_geo.items()):\n",
    "    query_doc = v\n",
    "    #similarity_value_dict = dict()\n",
    "    new_similarity_dict = bm25.get_score(query_doc)\n",
    "    #final_similarity_dict = {}\n",
    "    final_similarity_dict[k] = new_similarity_dict\n",
    "    print(k)\n",
    "    write_res.write(res_addr  + k + '.txt', new_similarity_dict)\n",
    "    auto_rank.find_citations(k, list(new_similarity_dict.keys())) #keys are a list of pmids\n",
    "    \n",
    "a, b, c, d = auto_rank.get_values() #need to modify this \n",
    "print('good geo recommendations = {}, top1 hit geo recommendations = {}, bad geo recommendations = {}, '\n",
    "      'geo without citations = {}'.format(a, b, c, d))\n",
    "#we need many more than just MRR\n",
    "filename =  res_addr + 'new_similarity_dict.pickle'\n",
    "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "with open(res_addr + 'new_similarity_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(final_similarity_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_addr = 'results/bm25_plain/smallbase/'\n",
    "with open(res_addr +'new_similarity_dict.pickle', 'rb') as fp:\n",
    "    new_similarity_dict = pickle.load(fp)\n",
    "#MRR \n",
    "print('MRR:')\n",
    "print(Metrics(citation_data).calculate_mrr(new_similarity_dict)) #mrr\n",
    "#recall @1 and recall @10\n",
    "print('recall@1, recall@10:')\n",
    "print(Metrics(citation_data).calculate_recall_at_k(new_similarity_dict, 1))\n",
    "print(Metrics(citation_data).calculate_recall_at_k(new_similarity_dict, 10))\n",
    "#Precision@1 and precision10\n",
    "print('precision@1, precision@10:')\n",
    "print(Metrics(citation_data).calculate_precision_at_k(new_similarity_dict, 1))        \n",
    "print(Metrics(citation_data).calculate_precision_at_k(new_similarity_dict, 10))\n",
    "#MAP@10\n",
    "print(Metrics(citation_data).calculate_MAP_at_k(new_similarity_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. time it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('joined_dict_geo', 'rb') as fp:\n",
    "    joined_dict_geo = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_similarity_dict = {}\n",
    "timeit_ls = []\n",
    "for step, (k,v) in enumerate(joined_dict_geo.items()):\n",
    "    start_time = time.time()\n",
    "    query_doc = clean(v)\n",
    "    #similarity_value_dict = dict()\n",
    "    new_similarity_dict = bm25.get_score(query_doc)\n",
    "    end_time = time.time()\n",
    "    secs = end_time - start_time\n",
    "    timeit_ls.append(secs)\n",
    "    if step > 100:\n",
    "        break\n",
    "\n",
    "print(np.mean(np.array(timeit_ls))) \n",
    "#print(np.mean(np.array(timeit_ls))/b_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. pick some cases for discussion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,v in new_similarity_dict.items():\n",
    "    print(k,v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in citation_data.items():\n",
    "    print(k,v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in title_ws.items():\n",
    "    print(k,v)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
