{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality Summary\n",
    "In this notebook, we did\n",
    "* Baseline experiments for doc2vec \n",
    "* built the whole vocabulary on the RFA and testing on publications belonging to the test data\n",
    "* all evaluations are done on the test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import argparse \n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging \n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.metrics.pairwise import linear_kernel\n",
    "#from gensim import corpora\n",
    "#from gensim.summarization import bm25\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "# from gensim.models.word2vec import Word2Vec\n",
    "#from gensim.test.utils import get_tmpfile\n",
    "\n",
    "#local \n",
    "import utils_bsl as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the order that they will be used\n",
    "parser = argparse.ArgumentParser(description = 'doc2vec for Grant recommendation')\n",
    "parser.add_argument('-data_path', type = str, default = 'newdata/', \n",
    "                    help = 'complete path to the training data [default:newdata/]')\n",
    "parser.add_argument('-load_pretrained', type = bool, default = True,\n",
    "                    help = 'whether to load pretrained doc2vec embeddings & corpus & vectorizer [default:False]')\n",
    "parser.add_argument('-load_path', type = str, default = 'evalAuto/doc2vec/', \n",
    "                    help = 'path where doc2vec embeddings & corpus & vectorizers are saved [default:evalAuto/doc2vec/]')\n",
    "# some training parameters regarding word2vec\n",
    "parser.add_argument('-vector_size', type = int, default = 200, \n",
    "                    help = 'document vector dimension [default:200]')\n",
    "parser.add_argument('-min_count', type = int, default = 2, \n",
    "                    help = 'vector minimun count [default:2]')\n",
    "parser.add_argument('-epochs', type = int, default = 100, \n",
    "                    help = 'training epochs [default:50]')\n",
    "parser.add_argument('-workers', type = int, default = 4, \n",
    "                    help = 'number of workers for model [default:4]')\n",
    "parser.add_argument('-top', type = int, default = 10, \n",
    "                    help = 'number of recommendations to take [default:10]')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    seed_val = 1234\n",
    "    ut.set_seed(seed_val) \n",
    "    \n",
    "    # get logger started\n",
    "    logging.basicConfig(level=logging.ERROR, filename= args.load_path + \"logfile\", filemode=\"a+\",\n",
    "                            format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "    logger = logging.getLogger('doc2vec for grant')\n",
    "    handler = logging.FileHandler(args.load_path + \"logfile\")\n",
    "    logger.addHandler(handler)\n",
    "    logger.error('doc2vec for grant')\n",
    "    \n",
    "    try:\n",
    "        # train, valid and test \n",
    "        rfas, pubs, mix_df, \\\n",
    "        train_idx, valid_idx, test_idx, \\\n",
    "        train_citation, valid_citation, citation, \\\n",
    "        train_mixed, valid_mixed, test_mixed = ut.load_data(args.data_path)\n",
    "        \n",
    "        model, rfa_ids = ut.process_rfa_corpus_d2v(df = rfas, outpath = args.load_path, args = args, \\\n",
    "                                                               load_pretrained = args.load_pretrained)\n",
    "        train_sims , train_pmids, _ = ut.process_pub_query_d2v(idx = train_idx, mix_df = mix_df, pubs = pubs, \n",
    "                                                          model = model,\\\n",
    "                                                          idx_name = 'train_', \\\n",
    "                                                          outpath = args.load_path, \\\n",
    "                                                          load_pretrained = args.load_pretrained)\n",
    "        valid_sims, valid_pmids, _  = ut.process_pub_query_d2v(idx = valid_idx, mix_df = mix_df, pubs = pubs, \n",
    "                                                          model = model,\\\n",
    "                                                          idx_name = 'valid_', \\\n",
    "                                                          outpath = args.load_path, \\\n",
    "                                                          load_pretrained = args.load_pretrained)\n",
    "        test_sims, test_pmids, _ = ut.process_pub_query_d2v(idx = test_idx, mix_df = mix_df, pubs = pubs, \n",
    "                                                          model = model,\\\n",
    "                                                          idx_name = 'test_', \\\n",
    "                                                          outpath = args.load_path, \\\n",
    "                                                          load_pretrained = args.load_pretrained)\n",
    "        train_dict = ut.sim_recommend_d2v(corpus_ids = rfa_ids,\\\n",
    "                                       sims = train_sims, query_ids = train_pmids, \n",
    "                                       mix_dict = train_mixed, mode= 'strict',outpath = args.load_path, \\\n",
    "                                       query_name = 'train_', top= args.top) \n",
    "        valid_dict = ut.sim_recommend_d2v(corpus_ids = rfa_ids,\\\n",
    "                                       sims = valid_sims, query_ids = valid_pmids, \n",
    "                                       mix_dict = valid_mixed, mode= 'strict',outpath = args.load_path, \\\n",
    "                                       query_name = 'valid_', top= args.top) \n",
    "        test_dict = ut.sim_recommend_d2v(corpus_ids = rfa_ids,\\\n",
    "                                         sims = test_sims, query_ids = test_pmids, \n",
    "                                         mix_dict = test_mixed, mode= 'strict',outpath = args.load_path, \\\n",
    "                                         query_name = 'test_', top= args.top) \n",
    "        \n",
    "\n",
    "        # evaluation on train and test \n",
    "        logger.error('=======train statistics======')\n",
    "        ut.print_metrics(citation = train_citation, similarity_dict = train_dict, logger = logger, ks = [1, 5])\n",
    "        print('=========================================')\n",
    "        logger.error('=======test statistics======')\n",
    "        ut.print_metrics(citation = citation, similarity_dict = test_dict, logger = logger, ks = [1, 5])\n",
    "        logging.shutdown()\n",
    "        for handler in logger.handlers:\n",
    "            if isinstance(handler, logging.FileHandler):\n",
    "                handler.close()\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(colored('--' * 70, 'green'))\n",
    "        print(colored('Exiting from training early', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
