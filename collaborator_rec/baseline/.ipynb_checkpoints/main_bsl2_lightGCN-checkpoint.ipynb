{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ec5c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# basics \n",
    "from os.path import exists\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "from torch_sparse import SparseTensor\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "# pytorch geometric \n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import TemporalData\n",
    "\n",
    "# local\n",
    "from prepare_data_bsl import yearly_authors\n",
    "from prepare_dataset_bsl import CollabDataset\n",
    "import utils_bsl as ut \n",
    "from myLightGCN import LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # define arguments\n",
    "    parser = argparse.ArgumentParser('baseline link predictions--lightGCN')\n",
    "    # data \n",
    "    parser.add_argument( '--data', type=str, help='collab for our own experiments',\n",
    "                    default='collab')\n",
    "    parser.add_argument('--yrs', default = [2010,2011], type = int, help='years to work on')\n",
    "    parser.add_argument('--authfile', default = '../../part0_GrantRec/newdata/processed_pubs.pickle', \\\n",
    "                        help='crawed pubmed database')\n",
    "    parser.add_argument('--inpath', default = '../sage/mesh/20102011/', \\\n",
    "                        help=\"since we are using the same dataset as the SAGE, we can reuse the processed dataset\")\n",
    "    parser.add_argument('--node_options', default = 'mesh', \\\n",
    "                        help=\"node feature options, choose from mesh/pubs\")\n",
    "    parser.add_argument('--savepath', type=str, help='path to save the data',\n",
    "                    default='20102011_mesh/')    \n",
    "    parser.add_argument('--bs', type=int, default= 1024, help='Batch_size')\n",
    "\n",
    "    # model \n",
    "    parser.add_argument('--embedding_dim', type=int, default=200, help='embedding dimensions') \n",
    "    parser.add_argument('--num_layers', type=int, default=2, help='number of lightgcn layers')\n",
    "    parser.add_argument('--lr', type=float, default=0.005, help='Learning rate')\n",
    "    parser.add_argument('--gpu', type=int, default=0, help='GPU index to use if built trees on GPU')\n",
    "    # training \n",
    "    parser.add_argument('--n_epoch', type=int, default= 100, help='Number of epochs')\n",
    "    parser.add_argument('--seed', type=int, default=2021, help='One seed that rules them all')\n",
    "    args = parser.parse_args([])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args) \n",
    "    if not (exists(args.inpath + 'collabs_masks.csv') and exists(args.inpath + 'node_feats.npy')):\n",
    "        yearly_authors(authfile = args.authfile, years = args.yrs, savepath = args.inpath, options = args.node_options) \n",
    "        # dataset processing (graph)\n",
    "        dataset = CollabDataset(raw_dir = args.inpath)\n",
    "    \n",
    "    # original data\n",
    "    device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device {device}.\")\n",
    "    df = pd.read_csv(args.inpath + 'collabs_masks.csv')\n",
    "    node_feats = np.load(args.inpath + 'node_feats.npy')\n",
    "    node_feats = torch.tensor(node_feats, dtype = torch.float).to(device)\n",
    "    \n",
    "    # prepare data \n",
    "    data = TemporalData(\n",
    "    src= torch.tensor(df.new_author.to_list()),\n",
    "    dst=torch.tensor(df.new_coauthor.to_list()),\n",
    "    t= torch.tensor(df.timestamp.to_list()))\n",
    "    data.train_mask = torch.tensor(df.train_mask.to_list(), dtype= torch.bool)\n",
    "    data.val_mask = torch.tensor(df.val_mask.to_list(), dtype= torch.bool)\n",
    "    data.test_mask = torch.tensor(df.test_mask.to_list(), dtype= torch.bool)\n",
    "    data.edge_index  = torch.stack([data.src, data.dst])\n",
    "    train, val, test = data[data.train_mask], data[data.val_mask], data[data.test_mask]\n",
    "    \n",
    "    \n",
    "    logger = ut.create_log(args)\n",
    "    model = LightGCN(num_node = node_feats.shape[0], num_feat = node_feats.shape[1], \\\n",
    "                 embedding_dim = args.embedding_dim, num_layers = args.num_layers)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    # training and validation \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    train_iter = math.ceil(train.num_events/args.bs) \n",
    "    val_iter = math.ceil(val.num_events/args.bs) \n",
    "\n",
    "    for epoch in range(args.n_epoch):\n",
    "        total_loss = 0. \n",
    "        model.train()\n",
    "\n",
    "        for i in range(train_iter):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Sample negative destination nodes.\n",
    "            src, pos_dsc, neg_dsc = ut.sample_mini_batch(batch_size = args.bs, i = i, edge_index = train.edge_index)\n",
    "            pos = torch.cat([src.reshape(1,-1), pos_dsc.reshape(1,-1)])\n",
    "            neg = torch.cat([src.reshape(1,-1), neg_dsc.reshape(1,-1)])\n",
    "            batch_edge_index = torch.cat ([pos, neg], dim = 1 ).to(device) # 2x (batchdize *2)\n",
    "            #break \n",
    "\n",
    "            preds = model.predict_link( X= node_feats, edge_index = batch_edge_index)  \n",
    "            #print(preds.shape, preds)\n",
    "\n",
    "            batch_edge_label= torch.cat([torch.ones(pos.shape[1], preds.shape[1], dtype = torch.float),\n",
    "                                         torch.zeros(neg.shape[1], preds.shape[1], dtype = torch.float)]).to(device)\n",
    "            #print(batch_edge_label.shape, batch_edge_label)\n",
    "            loss = criterion(preds, batch_edge_label)\n",
    "            #print(loss)\n",
    "            #break\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += float(loss) * src.shape[0]\n",
    "\n",
    "        train_losses.append(total_loss)\n",
    "\n",
    "        val_loss  =0.\n",
    "        model.eval()\n",
    "        for j in range(val_iter):\n",
    "            with torch.no_grad():\n",
    "                # Sample negative destination nodes.\n",
    "                src, pos_dsc, neg_dsc = ut.sample_mini_batch(batch_size = args.bs, i = j, edge_index = val.edge_index)\n",
    "                pos = torch.cat([src.reshape(1,-1), pos_dsc.reshape(1,-1)])\n",
    "                neg = torch.cat([src.reshape(1,-1), neg_dsc.reshape(1,-1)])\n",
    "\n",
    "                batch_edge_index = torch.cat ([pos, neg], dim = 1 ).to(device) # 2x (batchdize *2)\n",
    "                preds = model.predict_link( X= node_feats, edge_index = batch_edge_index) \n",
    "\n",
    "                batch_edge_label= torch.cat([torch.ones(pos.shape[1], preds.shape[1], dtype = torch.float),\n",
    "                                             torch.zeros(neg.shape[1], preds.shape[1], dtype = torch.float)]).to(device)\n",
    "                loss = criterion(preds, batch_edge_label)\n",
    "\n",
    "                val_loss += float(loss)*src.shape[0]\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    plt.plot(range(1,args.n_epoch +1), train_losses, 'g', label='Training loss')\n",
    "    #plt.plot(range(1, args.n_epoch +1), val_losses, 'b', label='validation loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show();\n",
    "    plt.plot(range(1, args.n_epoch +1), val_losses, 'b', label='validation loss')\n",
    "    plt.title('validation loss')\n",
    "    plt.show();\n",
    "    \n",
    "    \n",
    "    #test\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    test_iter = math.ceil(test.num_events/args.bs) \n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for j in range(test_iter):\n",
    "        with torch.no_grad():\n",
    "            # Sample negative destination nodes.\n",
    "            src, pos_dsc, neg_dsc = ut.sample_mini_batch(batch_size = args.bs, i = j, edge_index = test.edge_index)\n",
    "            pos = torch.cat([src.reshape(1,-1), pos_dsc.reshape(1,-1)])\n",
    "            neg = torch.cat([src.reshape(1,-1), neg_dsc.reshape(1,-1)])\n",
    "\n",
    "            batch_edge_index = torch.cat ([pos, neg], dim = 1 ).to(device) # 2x (batchdize *2)\n",
    "            preds = model.predict_link( X= node_feats, edge_index = batch_edge_index) \n",
    "\n",
    "            batch_edge_label= torch.cat([torch.ones(pos.shape[1], preds.shape[1], dtype = torch.float),\n",
    "                                         torch.zeros(neg.shape[1], preds.shape[1], dtype = torch.float)]).to(device)\n",
    "            loss = criterion(preds, batch_edge_label)\n",
    "\n",
    "            val_loss += float(loss)*src.shape[0]\n",
    "\n",
    "            predictions.append(preds)\n",
    "            labels.append(batch_edge_label)\n",
    "\n",
    "    flat_preds = torch.cat(predictions)  \n",
    "    flat_labels = torch.cat(labels)\n",
    "    ap = average_precision_score(flat_labels.cpu().numpy(), flat_preds.sigmoid().detach().cpu().numpy())\n",
    "    auc = roc_auc_score(flat_labels.cpu().numpy(), flat_preds.sigmoid().detach().cpu().numpy())\n",
    "    print('test auc = {}, test ap = {}'.format(auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
