{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a27e05a3",
   "metadata": {},
   "source": [
    "### The main file for training SAGE graph for link predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02aacf2",
   "metadata": {},
   "source": [
    "this main file should be similar to training main file, only difference is that \n",
    "* we'll give them the opportunity to filter the affiliations.\n",
    "* also we should aime to give top 30 instead (not too many), \n",
    "* with each recommended collaborator having pubmed page listed ['link'] = 'https://www.ncbi.nlm.nih.gov/pubmed/?term=' + pmid + author_in_concern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16268dce",
   "metadata": {},
   "source": [
    "now you will get into dataset preparation(graph construction), train, valid and test split, then train the model and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a083184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from os.path import exists \n",
    "import argparse\n",
    "import gc \n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "\n",
    "# torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# dgl \n",
    "import dgl\n",
    "from dgl.data.utils import save_graphs, load_graphs\n",
    "\n",
    "# local\n",
    "from prepare_servicedata import yearly_authors\n",
    "from prepare_servicedataset import CollabDataset\n",
    "from service import service\n",
    "from models import GraphSAGE, MLPPredictor, DotPredictor, Model\n",
    "import utils as ut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602eedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    parser = argparse.ArgumentParser(description='SAGE graph for collab recommendation service')\n",
    "    # processing data\n",
    "    parser.add_argument('--yrs', default= [2019, 2020, 2021], type = int,\n",
    "                        help='years of authors to build the GraphSAGE')\n",
    "    parser.add_argument('--authfile', default= 'sage/data/20192020/[2019, 2020]_.pickle',\n",
    "                        help='original crawled pubmed pickle that contains info about publication and authors')\n",
    "    parser.add_argument('--k', default = 1, \n",
    "                        help='negative sample ratio (vs existing links)')\n",
    "    parser.add_argument('--val_ratio', default = 0.2, type = float,\n",
    "                        help='the valiation data split')\n",
    "    parser.add_argument('--f_name', default= 'Melissa',\n",
    "                        help='first name of the user')\n",
    "    parser.add_argument('--l_name', default= 'Valerio-Shewmaker',\n",
    "                        help='last name of the user')\n",
    "    parser.add_argument('--m_name', default= 'A',\n",
    "                        help='middle name of the user')\n",
    "    parser.add_argument('--exclude', default= '', type=str,\n",
    "                        help='a list of names(string) to exclude from the collaborator recommendations')\n",
    "    # model\n",
    "    parser.add_argument('--in_feats', default = 2000,\n",
    "                        help='input dimension of GraphSAGE, tfidf vector size 2000')\n",
    "    parser.add_argument('--node_options', default= 'pubs', type = str,\n",
    "                        help='the info to build node features on, choose from: pubs, mesh')\n",
    "    parser.add_argument('--h_feats', default = 50,\n",
    "                        help='embedding dimension of GraphSAGE output')\n",
    "    parser.add_argument('--out_feats', default = 2,\n",
    "                        help='output dimension of model, link prediction of 2')\n",
    "    parser.add_argument('--sage_pool', default= ['gcn','gcn'], type = str,\n",
    "                        help='aggregation types for the 2-layer GraphSAGE, choose from : mean, pool, gcn')\n",
    "    # training \n",
    "    parser.add_argument('--lr', default= 0.003, # try another lr 0.001 to 0.005 \n",
    "                        help='learning rate of the optimizer')\n",
    "    parser.add_argument('--wd', default= 0.00001,\n",
    "                        help='weigth decay of the optimizer')    \n",
    "    parser.add_argument('--epochs', default= 100,\n",
    "                        help='training epochs')\n",
    "    parser.add_argument('--GPU', default= 0,\n",
    "                        help='index for GPU')\n",
    "    parser.add_argument('--save_path', default= 'service/',\n",
    "                        help='main path to store model and prediction results for GraphSAGE')\n",
    "    # recommend \n",
    "    parser.add_argument('--firstk', default= 30,\n",
    "                        help='number of collaborators to show on the recommendation list')\n",
    "    args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50547d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    #part 2. training\n",
    "    if args.m_name.strip() == '':\n",
    "        name_suff = args.f_name + '_'  + args.l_name + '/'\n",
    "    else:\n",
    "        name_suff = args.f_name + '_' +  args.m_name +  '_' + args.l_name + '/'\n",
    "\n",
    "    res_path = args.save_path  +  name_suff +  args.node_options + '/' #create new path\n",
    "\n",
    "    if exists(res_path + 'sageGraph.bin'):\n",
    "        graph = load_graphs(res_path + \"sageGraph.bin\")[0][0]\n",
    "        if not 'label' in graph.edata:\n",
    "            graph.edata['label'] = torch.ones(graph.num_edges(), dtype= torch.long)\n",
    "            save_graphs(res_path + 'sageGraph.bin', [graph])\n",
    "    else:\n",
    "        if not (exists(res_path + 'collabs.csv') and exists(res_path + 'authors.csv')):\n",
    "            serv = service(f_name = args.f_name, l_name = args.l_name, m_name = args.m_name, \\\n",
    "                     path = args.save_path, years = args.yrs, pubfile = args.authfile, \\\n",
    "                     exclude_users = args.exclude, options = args.node_options, val_ratio = args.val_ratio)\n",
    "        # dataset processing (graph)\n",
    "        dataset = CollabDataset(raw_dir = res_path)\n",
    "        graph = dataset[0]\n",
    "        # add labels\n",
    "        if not 'label' in graph.edata: \n",
    "            graph.edata['label'] = torch.ones(graph.num_edges(), dtype= torch.long)\n",
    "        save_graphs(res_path  + 'sageGraph.bin', [graph])\n",
    "    print(graph)\n",
    "    # print(graph.device)\n",
    "\n",
    "    # prepare negatives as well \n",
    "    graph = ut.construct_negEdges(graph, k = args.k, newNode = False , service = True)                                        \n",
    "    # train, validation, and test split \n",
    "    train_g, val_g, test_g =  ut.inductive_edge_split(graph, newNode = False)\n",
    "    train_feats, train_y = ut.feat_labels(train_g)\n",
    "    val_feats, val_y = ut.feat_labels(val_g)\n",
    "    test_feats, test_y = ut.feat_labels(test_g)\n",
    "\n",
    "    # logs                     \n",
    "    logger = ut.create_log(args)             \n",
    "    # device\n",
    "    device_string = 'cuda:{}'.format(args.GPU) if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device_string)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "    with torch.cuda.device(device_string):\n",
    "        torch.cuda.empty_cache()   \n",
    "\n",
    "    # model \n",
    "    model = Model(in_features = args.in_feats, hidden_features = args.h_feats, out_features =args.out_feats, \\\n",
    "                  pool = args.sage_pool)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr= args.lr,  weight_decay = args.wd)\n",
    "    loss_fcn = nn.CrossEntropyLoss()  \n",
    "\n",
    "    model = ut.train_epochs(logger = logger, epochs=  args.epochs, model = model, \n",
    "                    train_g = train_g, train_feats = train_feats, train_y = train_y, \\\n",
    "                     val_g = val_g, val_feats = val_feats, val_y = val_y, \\\n",
    "                     new_val_g =val_g, new_val_feats = val_feats, new_val_y = val_y,\\\n",
    "                     device = device, opt = opt, loss_fcn = loss_fcn, path = res_path, every = 5, newNode = False )\n",
    "\n",
    "\n",
    "    # recommend\n",
    "    author_dict = pickle.load(open(res_path + 'author_refs.pickle', 'rb'))\n",
    "    ut.recommend(logger = logger, model = model, \\\n",
    "                    test_g = test_g, test_feats = test_feats, test_y = test_y,\\\n",
    "                    device =device, author_dict = author_dict, firstk = args.firstk, path = res_path, \\\n",
    "                    f_name = args.f_name, l_name = args.l_name, m_name = args.m_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca8b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a665f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7133a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1c685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3dd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9a752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ee987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
