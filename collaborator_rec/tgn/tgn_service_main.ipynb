{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2dab66",
   "metadata": {},
   "source": [
    "### The main file for training TGN  for link predictions\n",
    "\n",
    "Before running this file, be sure to run the data preparation as below if not already exist\n",
    "\n",
    "1. using python utils/prepare_data.py --years [xxxxxxxxx]\n",
    "2. get the graph data prepared as told:python utils/preprocess_data.py --data collab --bipartite 'FALSE'\n",
    "3. finally run the link predictions:this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librries\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# local\n",
    "import utils.utils as ut\n",
    "from utils.preprocessing_servicedata_tgn import run\n",
    "from utils.utils import EarlyStopMonitor, RandEdgeSampler, get_neighbor_finder\n",
    "from utils.data_servicepreprocessing_tgn import get_data, compute_time_statistics\n",
    "from evaluation.evaluation import eval_edge_prediction\n",
    "from model.tgn import TGN\n",
    "from service_tgn import service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6712b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "    parser = argparse.ArgumentParser('TGN temporal link predictions')\n",
    "    # data \n",
    "    parser.add_argument( '--data', type=str, help='collab for our own experiments, others include benchmark wikipedia',\n",
    "                    default='collab')\n",
    "    parser.add_argument('--bipartite', default = False, help='Whether the graph is bipartite')\n",
    "    parser.add_argument('--yrs', default = [2019, 2020], type = int, help='years to work on ')\n",
    "    parser.add_argument('--authfile', default = 'data/20192020/[2019, 2020]_.pickle', \\\n",
    "                        help='crawed pubmed database')\n",
    "    parser.add_argument('--savepath', type=str, help='which period to experiment on',\n",
    "                    default='service/')\n",
    "    parser.add_argument('--different_new_nodes', default = False,\n",
    "                    help='Whether to use disjoint set of new nodes for train and val')\n",
    "    parser.add_argument('--bs', type=int, default= 10, help='Batch_size')\n",
    "    parser.add_argument('--prefix', type=str, default='', help='Prefix to name the checkpoints')\n",
    "    parser.add_argument('--val_ratio', default = 0.2, type = float,\n",
    "                        help='the valiation data split')\n",
    "    parser.add_argument('--f_name', default= 'Vahed',\n",
    "                        help='first name of the user')\n",
    "    parser.add_argument('--l_name', default= 'Maroufy',\n",
    "                        help='last name of the user')\n",
    "    parser.add_argument('--m_name', default= '',\n",
    "                        help='middle name of the user')\n",
    "    parser.add_argument('--exclude', default= '', type=str,\n",
    "                        help='a list of names(string) to exclude from the collaborator recommendations')\n",
    "    \n",
    "    # model \n",
    "    parser.add_argument('--n_degree', type=int, default=5, help='Number of neighbors to sample') #25/10 for SAGE\n",
    "    parser.add_argument('--uniform', action='store_true',\n",
    "                    help='take uniform sampling from temporal neighbors')\n",
    "    parser.add_argument('--n_layer', type=int, default=1, help='Number of network layers')\n",
    "    parser.add_argument('--n_head', type=int, default=2, help='Number of heads used in attention layer')\n",
    "    parser.add_argument('--drop_out', type=float, default=0.1, help='Dropout probability')\n",
    "    parser.add_argument('--node_dim', type=int, default=200, help='Dimensions of the node embedding')\n",
    "    parser.add_argument('--time_dim', type=int, default=5, help='Dimensions of the time embedding') \n",
    "    parser.add_argument('--backprop_every', type=int, default= 100, help='Every how many batches to '\n",
    "                                                                  'backprop')\n",
    "    ## memory \n",
    "    parser.add_argument('--use_memory', default= False,\n",
    "                    help='Whether to augment the model with a node memory')\n",
    "    parser.add_argument('--memory_updater', type=str, default=\"gru\", \\\n",
    "                        choices=[\"gru\", \"rnn\"], help='Type of memory updater')\n",
    "    parser.add_argument('--memory_update_at_end', default = False,\n",
    "                    help='Whether to update memory at the end or at the start of the batch')\n",
    "    parser.add_argument('--memory_dim', type=int, default= 172, help='Dimensions of the memory for '\n",
    "                                                                'each user') #172\n",
    "    ## message \n",
    "    parser.add_argument('--message_function', type=str, default=\"identity\", \\\n",
    "                        choices=[\"mlp\", \"identity\"], help='Type of message function')\n",
    "    parser.add_argument('--use_source_embedding_in_message', default = True,\n",
    "                    help='Whether to use the embedding of the source node as part of the message')\n",
    "    parser.add_argument('--use_destination_embedding_in_message', default = True,\n",
    "                    help='Whether to use the embedding of the destination node as part of the message')\n",
    "    parser.add_argument('--aggregator', type=str, default=\"last\", help='Type of message '\n",
    "                                                                        'aggregator')\n",
    "    parser.add_argument('--message_dim', type=int, default=50, help='Dimensions of the messages') #100\n",
    "    ## embedding \n",
    "    parser.add_argument('--embedding_module', type=str, default=\"graph_attention\", \\\n",
    "                        choices=[\"graph_attention\", \"graph_sum\", \"identity\", \"time\"], help='Type of embedding module')\n",
    "    parser.add_argument('--randomize_features', default = False,\n",
    "                    help='Whether to randomize node features')\n",
    "    parser.add_argument('--node_options', default = 'pubs', help='whether use mesh/pubs for the node features')\n",
    "    parser.add_argument('--dyrep', default = False,\n",
    "                    help='Whether to run the dyrep model')\n",
    "    # training \n",
    "    parser.add_argument('--n_epoch', type=int, default=100, help='Number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001, help='Learning rate')\n",
    "    parser.add_argument('--patience', type=int, default=20, help='Patience for early stopping')\n",
    "    parser.add_argument('--n_runs', type=int, default=1, help='Number of runs')\n",
    "    parser.add_argument('--gpu', type=int, default=0, help='Idx for the gpu to use')\n",
    "    parser.add_argument('--seed', type=int, default=2021, help='One seed that rules them all')\n",
    "    \n",
    "    # service\n",
    "    parser.add_argument('--firstk', type=int, default=30, help='number of collaborators to recommend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b5099",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  args = parser.parse_args([])\n",
    "except:\n",
    "  parser.print_help()\n",
    "  sys.exit(0)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "\n",
    "if args.m_name.strip() == '':\n",
    "    name_suff = args.f_name + '_'  + args.l_name + '/'\n",
    "else:\n",
    "    name_suff = args.f_name + '_' +  args.m_name +  '_' + args.l_name + '/'\n",
    "# we only save user related files here \n",
    "res_path = args.savepath  +  name_suff + args.node_options + '/'\n",
    "\n",
    "BATCH_SIZE = args.bs\n",
    "NUM_NEIGHBORS = args.n_degree\n",
    "NUM_NEG = 1\n",
    "NUM_EPOCH = args.n_epoch\n",
    "NUM_HEADS = args.n_head\n",
    "DROP_OUT = args.drop_out\n",
    "GPU = args.gpu\n",
    "DATA = args.data\n",
    "NUM_LAYER = args.n_layer\n",
    "LEARNING_RATE = args.lr\n",
    "NODE_DIM = args.node_dim\n",
    "TIME_DIM = args.time_dim\n",
    "USE_MEMORY = args.use_memory\n",
    "MESSAGE_DIM = args.message_dim\n",
    "MEMORY_DIM = args.memory_dim\n",
    "\n",
    "Path(\"./saved_models/\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"./saved_checkpoints/\").mkdir(parents=True, exist_ok=True)\n",
    "MODEL_SAVE_PATH = f'./saved_models/{args.node_options}-{args.data}.pth'\n",
    "get_checkpoint_path = lambda \\\n",
    "    epoch: f'./saved_checkpoints/{args.node_options}-{args.data}-{epoch}.pth'\n",
    "\n",
    "### set up logger\n",
    "logger= ut.make_log(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing data part\n",
    "serv = service(f_name = args.f_name, l_name = args.l_name, m_name = args.m_name, path = '../service/', \\\n",
    "               years = args.yrs, pubfile = args.authfile, exclude_users = args.exclude, options = args.node_options,\\\n",
    "               val_ratio = args.val_ratio)\n",
    "run(args.data, rand_node_feat = args.randomize_features, bipartite=args.bipartite, path = res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c74af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract data for training, validation and testing\n",
    "node_features, edge_features, full_data, train_data, val_data, test_data = get_data(DATA,\\\n",
    "                              different_new_nodes_between_val_and_test=args.different_new_nodes, \\\n",
    "                              randomize_features=args.randomize_features,\n",
    "                              path= res_path)\n",
    "# Initialize training neighbor finder to retrieve temporal graph\n",
    "train_ngh_finder = get_neighbor_finder(train_data, args.uniform)\n",
    "\n",
    "# Initialize validation and test neighbor finder to retrieve temporal graph\n",
    "full_ngh_finder = get_neighbor_finder(full_data, args.uniform)\n",
    "\n",
    "# Initialize negative samplers. Set seeds for validation and testing so negatives are the same\n",
    "# across different runs\n",
    "# NB: in the inductive setting, negatives are sampled only amongst other new nodes\n",
    "train_rand_sampler = RandEdgeSampler(train_data.sources, train_data.destinations)\n",
    "val_rand_sampler = RandEdgeSampler(full_data.sources, full_data.destinations, seed= args.seed)\n",
    "test_rand_sampler = RandEdgeSampler(full_data.sources, full_data.destinations, seed=args.seed+1)\n",
    "\n",
    "device_string = 'cuda:{}'.format(GPU) if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_string)\n",
    "\n",
    "# Compute time statistics\n",
    "mean_time_shift_src, std_time_shift_src, mean_time_shift_dst, std_time_shift_dst = \\\n",
    "  compute_time_statistics(full_data.sources, full_data.destinations, full_data.timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6ab45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(args.n_runs):\n",
    "  results_path = \"results/{}_{}.pkl\".format(args.prefix, i) if i > 0 else \"results/{}.pkl\".format(args.node_options)\n",
    "  Path(\"results/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  # Initialize Model: check this\n",
    "  tgn = TGN(neighbor_finder=train_ngh_finder, node_features=node_features,\n",
    "            edge_features=edge_features, device=device,\n",
    "            n_layers=NUM_LAYER,\n",
    "            n_heads=NUM_HEADS, dropout=DROP_OUT, use_memory=USE_MEMORY,\n",
    "            message_dimension=MESSAGE_DIM, memory_dimension=MEMORY_DIM,\n",
    "            memory_update_at_start=not args.memory_update_at_end,\n",
    "            embedding_module_type=args.embedding_module, #let's see how it goes\n",
    "            message_function=args.message_function,\n",
    "            aggregator_type=args.aggregator,\n",
    "            memory_updater_type=args.memory_updater,\n",
    "            n_neighbors=NUM_NEIGHBORS,\n",
    "            mean_time_shift_src=mean_time_shift_src, std_time_shift_src=std_time_shift_src,\n",
    "            mean_time_shift_dst=mean_time_shift_dst, std_time_shift_dst=std_time_shift_dst,\n",
    "            use_destination_embedding_in_message=args.use_destination_embedding_in_message,\n",
    "            use_source_embedding_in_message=args.use_source_embedding_in_message,\n",
    "            dyrep=args.dyrep)\n",
    "  criterion = torch.nn.BCELoss()\n",
    "  optimizer = torch.optim.Adam(tgn.parameters(), lr=LEARNING_RATE)\n",
    "  tgn = tgn.to(device)\n",
    "\n",
    "  num_instance = len(train_data.sources)\n",
    "  num_batch = math.ceil(num_instance / BATCH_SIZE)\n",
    "\n",
    "  logger.info('num of training instances: {}'.format(num_instance))\n",
    "  logger.info('num of batches per epoch: {}'.format(num_batch))\n",
    "  idx_list = np.arange(num_instance)\n",
    "\n",
    "  val_aps = []\n",
    "  epoch_times = []\n",
    "  total_epoch_times = []\n",
    "  train_losses = []\n",
    "\n",
    "  early_stopper = EarlyStopMonitor(max_round=args.patience)\n",
    "  for epoch in range(NUM_EPOCH):\n",
    "    start_epoch = time.time()\n",
    "    ### Training\n",
    "\n",
    "    # Reinitialize memory of the model at the start of each epoch\n",
    "    if USE_MEMORY:\n",
    "      tgn.memory.__init_memory__()\n",
    "\n",
    "    # Train using only training graph\n",
    "    tgn.set_neighbor_finder(train_ngh_finder)\n",
    "    m_loss = []\n",
    "\n",
    "    logger.info('start {} epoch'.format(epoch))\n",
    "    for k in range(0, num_batch, args.backprop_every):\n",
    "      loss = 0\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Custom loop to allow to perform backpropagation only every a certain number of batches\n",
    "      for j in range(args.backprop_every):\n",
    "        batch_idx = k + j\n",
    "\n",
    "        if batch_idx >= num_batch:\n",
    "          continue\n",
    "\n",
    "        start_idx = batch_idx * BATCH_SIZE\n",
    "        end_idx = min(num_instance, start_idx + BATCH_SIZE)\n",
    "        sources_batch, destinations_batch = train_data.sources[start_idx:end_idx], \\\n",
    "                                            train_data.destinations[start_idx:end_idx]\n",
    "        edge_idxs_batch = train_data.edge_idxs[start_idx: end_idx]\n",
    "        timestamps_batch = train_data.timestamps[start_idx:end_idx]\n",
    "\n",
    "        size = len(sources_batch)\n",
    "        _, negatives_batch = train_rand_sampler.sample(size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "          pos_label = torch.ones(size, dtype=torch.float, device=device)\n",
    "          neg_label = torch.zeros(size, dtype=torch.float, device=device)\n",
    "\n",
    "        tgn = tgn.train()\n",
    "        # check if the device are consistant\n",
    "        pos_prob, neg_prob = tgn.compute_edge_probabilities(sources_batch, destinations_batch, negatives_batch,\n",
    "                                                            timestamps_batch, edge_idxs_batch, NUM_NEIGHBORS)\n",
    "\n",
    "        loss += criterion(pos_prob.squeeze(), pos_label) + criterion(neg_prob.squeeze(), neg_label)\n",
    "\n",
    "      loss /= args.backprop_every\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      m_loss.append(loss.item())\n",
    "\n",
    "      # Detach memory after 'args.backprop_every' number of batches so we don't backpropagate to\n",
    "      # the start of time\n",
    "      if USE_MEMORY:\n",
    "        tgn.memory.detach_memory()\n",
    "\n",
    "    epoch_time = time.time() - start_epoch\n",
    "    epoch_times.append(epoch_time)\n",
    "\n",
    "    ### Validation\n",
    "    # Validation uses the full graph\n",
    "    tgn.set_neighbor_finder(full_ngh_finder)\n",
    "\n",
    "    if USE_MEMORY:\n",
    "      # Backup memory at the end of training, so later we can restore it and use it for the\n",
    "      # validation on unseen nodes\n",
    "      train_memory_backup = tgn.memory.backup_memory()\n",
    "\n",
    "    val_ap, val_auc = eval_edge_prediction(model=tgn, negative_edge_sampler=val_rand_sampler,\n",
    "                                           data=val_data,\n",
    "                                           n_neighbors=NUM_NEIGHBORS, batch_size=BATCH_SIZE)\n",
    "    if USE_MEMORY:\n",
    "      val_memory_backup = tgn.memory.backup_memory()\n",
    "      # Restore memory we had at the end of training to be used when validating on new nodes.\n",
    "      # Also backup memory after validation so it can be used for testing (since test edges are\n",
    "      # strictly later in time than validation edges)\n",
    "      tgn.memory.restore_memory(train_memory_backup)\n",
    "\n",
    "\n",
    "    if USE_MEMORY:\n",
    "      # Restore memory we had at the end of validation\n",
    "      tgn.memory.restore_memory(val_memory_backup)\n",
    "\n",
    "    val_aps.append(val_ap)\n",
    "    train_losses.append(np.mean(m_loss))\n",
    "\n",
    "    # Save temporary results to disk\n",
    "    pickle.dump({\n",
    "      \"val_aps\": val_aps,\n",
    "      \"train_losses\": train_losses,\n",
    "      \"epoch_times\": epoch_times,\n",
    "      \"total_epoch_times\": total_epoch_times\n",
    "    }, open(results_path, \"wb\"))\n",
    "\n",
    "    total_epoch_time = time.time() - start_epoch\n",
    "    total_epoch_times.append(total_epoch_time)\n",
    "\n",
    "    logger.info('epoch: {} took {:.2f}s'.format(epoch, total_epoch_time))\n",
    "    logger.info('Epoch mean loss: {}'.format(np.mean(m_loss)))\n",
    "    logger.info(\n",
    "      'val auc: {}'.format(val_auc))\n",
    "    logger.info(\n",
    "      'val ap: {}'.format(val_ap))\n",
    "\n",
    "    # Early stopping\n",
    "    if early_stopper.early_stop_check(val_ap):\n",
    "      logger.info('No improvement over {} epochs, stop training'.format(early_stopper.max_round))\n",
    "      logger.info(f'Loading the best model at epoch {early_stopper.best_epoch}')\n",
    "      best_model_path = get_checkpoint_path(early_stopper.best_epoch)\n",
    "      tgn.load_state_dict(torch.load(best_model_path))\n",
    "      logger.info(f'Loaded the best model at epoch {early_stopper.best_epoch} for inference')\n",
    "      tgn.eval()\n",
    "      break\n",
    "    else:\n",
    "      torch.save(tgn.state_dict(), get_checkpoint_path(epoch))\n",
    "\n",
    "  # Training has finished, we have loaded the best model, and we want to backup its current\n",
    "  # memory (which has seen validation edges) so that it can also be used when testing on unseen\n",
    "  # nodes\n",
    "  if USE_MEMORY:\n",
    "    val_memory_backup = tgn.memory.backup_memory()\n",
    "\n",
    "  ### Test\n",
    "  tgn.embedding_module.neighbor_finder = full_ngh_finder\n",
    "    \n",
    "  ## define the test batches \n",
    "  num_test = len(test_data.sources)\n",
    "  test_batches = math.ceil(num_test/ BATCH_SIZE)\n",
    "  all_probs = []\n",
    "  with torch.no_grad():\n",
    "      for i in range(test_batches):\n",
    "          # define start_idx and end_idx\n",
    "          start_idx = i * BATCH_SIZE\n",
    "          end_idx = min(num_test, start_idx + BATCH_SIZE)\n",
    "\n",
    "          sources_batch, destinations_batch = test_data.sources[start_idx:end_idx], \\\n",
    "                                              test_data.destinations[start_idx:end_idx]\n",
    "          edge_idxs_batch = test_data.edge_idxs[start_idx: end_idx]\n",
    "          timestamps_batch = test_data.timestamps[start_idx:end_idx]\n",
    "          size = len(sources_batch)\n",
    "          _, negatives_batch = test_rand_sampler.sample(size)\n",
    "\n",
    "          # need to modify this negative_batch, cuz we won't have one\n",
    "          probs = ut.compute_edge_probabilities(tgn, sources_batch, destinations_batch, negatives_batch,\n",
    "                                                                timestamps_batch, edge_idxs_batch, NUM_NEIGHBORS)\n",
    "          all_probs.extend(probs)   \n",
    "    \n",
    "  #probs_flat = [item for sublist in all_probs for item in sublist]  \n",
    "  probs_flat = all_probs\n",
    "  probs_flat = [i.reshape(all_probs[0].shape) for i in probs_flat]\n",
    "  # let's write the prediction results\n",
    "  author_dict = pickle.load(open('data/' + res_path + 'author_refs.pickle', 'rb'))\n",
    "  ut.recommend(logger = logger, test_dst = test_data.destinations, probs = probs_flat, \\\n",
    "                device = device, author_dict = author_dict, firstk = args.firstk, path = res_path, \\\n",
    "                f_name = args.f_name, l_name = args.l_name, m_name = args.m_name)\n",
    "\n",
    "  if USE_MEMORY:\n",
    "    tgn.memory.restore_memory(val_memory_backup)\n",
    "\n",
    "\n",
    "  # Save results for this run\n",
    "  pickle.dump({\n",
    "    \"val_aps\": val_aps,\n",
    "    \"epoch_times\": epoch_times,\n",
    "    \"train_losses\": train_losses,\n",
    "    \"total_epoch_times\": total_epoch_times\n",
    "  }, open(results_path, \"wb\"))\n",
    "\n",
    "  logger.info('Saving TGN model')\n",
    "  if USE_MEMORY:\n",
    "    # Restore memory at the end of validation (save a model which is ready for testing)\n",
    "    tgn.memory.restore_memory(val_memory_backup)\n",
    "  torch.save(tgn.state_dict(), MODEL_SAVE_PATH)\n",
    "  logger.info('TGN model saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
